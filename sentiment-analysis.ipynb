{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc4b9ece-617c-4a8c-a93e-64bf32eea238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /opt/anaconda3/lib/python3.12/site-packages (2.14.1)\n",
      "Collecting wordsegment\n",
      "  Downloading wordsegment-1.3.1-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Downloading wordsegment-1.3.1-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: wordsegment\n",
      "Successfully installed wordsegment-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji wordsegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "716f20f3-892f-4b0e-b69b-6d17bfd4ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Sentiment Analysis for Financial Social Media\n",
    "\n",
    "## 1. Introduction\n",
    "- Goal: Compare sentiment models (VADER, FinBERT, DeBERTa) on financial social media data.\n",
    "- Data Sources: Reddit, Twitter, Financial News.\n",
    "- Focus: Preprocessing, Model Benchmarking, Sarcasm Detection.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from wordsegment import load, segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d63928f-e2bb-450c-beaa-f223cf315e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load()  # Load segmentation for hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70868acf-1997-4c16-bec5-ab65e3f2c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love <TICKER> :rocket::rocket::rocket: bull market\n"
     ]
    }
   ],
   "source": [
    "# Example Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\$\\w+', '<TICKER>', text)\n",
    "    text = re.sub(r'#(\\w+)', lambda m: ' '.join(segment(m.group(1))), text)\n",
    "    text = re.sub(r'http\\S+', '', text)  # remove URLs\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)  # remove mentions\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "example_text = \"I love $TSLA 🚀🚀🚀 #BullMarket\"\n",
    "print(preprocess_text(example_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6a8d517b-4c63-46e3-830d-b5298c746722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Sentiment: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/rickliu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# VADER Example\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "text_vader = \"Tesla stock is going to the moon! 🚀\"\n",
    "vader_result = sia.polarity_scores(text_vader)\n",
    "vader_sentiment = vader_result['compound']\n",
    "print(\"VADER Sentiment:\", vader_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1296f256-11d7-4068-bdf9-ee9d5c0d9b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinBERT Sentiment: Positive tensor([[0.0558, 0.0373, 0.9068]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# FinBERT Example\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "inputs = tokenizer(text_vader, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "finbert_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "finbert_pred = finbert_labels[torch.argmax(probs)]\n",
    "print(\"FinBERT Sentiment:\", finbert_pred, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdd6e578-9a5e-4c13-896c-2891c0f3d038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (5.28.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /opt/anaconda3/lib/python3.12/site-packages (0.19.1)\n",
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.12/site-packages (from tokenizers) (0.24.6)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.6.15)\n",
      "Downloading tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.44.2 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.21.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.21.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece protobuf\n",
    "!pip install --upgrade tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cdc284e6-51c8-4b51-acf1-d6e4e982c5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeBERTa Sentiment: Negative tensor([[0.3486, 0.3415, 0.3099]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# DeBERTa Example (Updated to v1 base)\n",
    "tokenizer_deberta = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "model_deberta = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", num_labels=3)\n",
    "\n",
    "inputs_deberta = tokenizer_deberta(text_vader, return_tensors=\"pt\")\n",
    "outputs_deberta = model_deberta(**inputs_deberta)\n",
    "probs_deberta = torch.nn.functional.softmax(outputs_deberta.logits, dim=-1)\n",
    "\n",
    "deberta_labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "deberta_pred = deberta_labels[torch.argmax(probs_deberta)]\n",
    "print(\"DeBERTa Sentiment:\", deberta_pred, probs_deberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8dc2a77c-4663-49df-bf05-6c960ecfe903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VADER</td>\n",
       "      <td>Compound: 0.000</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FinBERT</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[0.056, 0.037, 0.907]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DeBERTa</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[0.349, 0.341, 0.31]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model        Sentiment                                      Probabilities\n",
       "0    VADER  Compound: 0.000  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "1  FinBERT         Positive                              [0.056, 0.037, 0.907]\n",
       "2  DeBERTa         Negative                               [0.349, 0.341, 0.31]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_data = {\n",
    "    \"Model\": [\"VADER\", \"FinBERT\", \"DeBERTa\"],\n",
    "    \"Sentiment\": [f\"Compound: {vader_sentiment:.3f}\", finbert_pred, deberta_pred],\n",
    "    \"Probabilities\": [\n",
    "        str(vader_result),\n",
    "        [round(float(p), 3) for p in probs.detach().numpy().flatten()],\n",
    "        [round(float(p), 3) for p in probs_deberta.detach().numpy().flatten()]\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "from IPython.display import display\n",
    "\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4b82833f-2aaa-41f8-87e1-b622b9177f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd531619a19487ba56e650eac35b189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3157fbef6646bd8e594ce39097d8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1088994bf4416a9898d27bcfc6119f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb540a67b0b4f3da94fec6a6535a6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcasm Detection (placeholder sentiment): [{'label': 'POSITIVE', 'score': 0.9996737241744995}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use sentiment analysis as placeholder since no public sarcasm model is available\n",
    "sarcasm_detector = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "text_sarcasm = \"Oh great, another fantastic earnings miss. Just what we needed.\"\n",
    "sarcasm_result = sarcasm_detector(text_sarcasm)\n",
    "print(\"Sarcasm Detection (placeholder sentiment):\", sarcasm_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22cfc2e-3127-4597-a682-973e831e72b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
